# Ansys HFSS 优化脚本关键技术实现

本文档记录了在开发 `adaptive_optimize.py` 脚本时采用的关键技术和最佳实践。

## 1. 自适应单位处理 (Robust Unit Handling)

这是脚本最核心的健壮性保证。

- **问题**: Ansys HFSS返回的频率数据单位由项目设置决定，若在代码中硬编码单位假设（如假设是GHz），会导致在不同设置下出现严重bug。
- **解决方案**: 利用 `pyaedt` 的 `solution_data.units_sweeps` 字典。该字典包含了如 `{'Freq': 'GHz'}` 的键值对。
- **实现**: 
    1. 在 `evaluate_hfss` 函数中，首先读取 `freq_unit = solution_data.units_sweeps['Freq']`。
    2. 根据读取到的字符串 (`'GHz'`, `'MHz'`, `'Hz'` 等)，动态计算出一个转换因子，将任何单位的频率统一转换到脚本内部使用的GHz单位。
    3. 后续所有计算都在统一的GHz单位下进行，无需再做任何转换。
- **优势**: 使脚本能够自动适应不同的Ansys项目设置，无需修改代码，极为健壮。

## 2. 自适应参数空间 (Adaptive Parameter Space)

- **问题**: 传统的优化方法在整个优化过程中使用固定的参数边界，当参数空间很大时效率低下。
- **解决方案**: 采用“代际”(Generational)优化策略。
- **实现**:
    1. 将总迭代次数分为若干“代”。
    2. 在每一代结束后，提取该代中表现最好的一批结果（例如前25%）。
    3. 计算这批“精英”参数的均值和标准差。
    4. 以下一代的搜索空间被动态调整为 `mean ± factor * std_dev`。
    5. 同时，确保新的边界不会超出预设的绝对物理边界。
- **优势**: 随着优化的进行，搜索空间会自动向更有希望的区域“收缩”和“聚焦”，显著提高了收敛速度。

## 3. 结构化日志 (Structured Logging)

- **问题**: 需要一种方法来持久化、可追溯地记录每一次“昂贵”的仿真结果。
- **解决方案**: 使用Python的 `logging` 模块，将结果记录为CSV格式。
- **实现**:
    1. 创建一个 `setup_logging` 函数，用于初始化一个指向 `optimization_log.csv` 的文件处理器。
    2. 在首次创建文件时，写入包含所有参数名的CSV表头。
    3. 在 `evaluate_hfss` 函数的末尾，将时间戳、迭代信息、成本以及所有参数的当前值格式化为一行CSV文本，并写入日志。
- **优势**: 日志文件清晰、结构化，可被Excel或Pandas等工具轻松分析，为优化过程提供了完整的“实验记录”。
